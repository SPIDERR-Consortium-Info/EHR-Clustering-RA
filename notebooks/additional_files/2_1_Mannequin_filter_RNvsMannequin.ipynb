{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Import Schedule appointments (for validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe: Schedule data (n= 110131; pat= 2346)\n",
      "Dataframe: Physician Schedule data (n= 42514; pat= 2344)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Relevant Codes\n",
    "codes = pd.read_csv(r'/exports/reum/tdmaarseveen/RA_Clustering/new_data/offshoots/DAS_check/codes_poli_schedule.csv', sep='|')\n",
    "l_physician_codes = list(codes[codes['physician']==1]['type1_code'].unique())\n",
    "\n",
    "# Consults\n",
    "consults = pd.read_csv(r'../../new_data/offshoots/Dataplatform63/DF_REU_Schedule_validate_2023.csv', sep=';', parse_dates=True, header=None)\n",
    "consults.columns = ['type1_code', 'type1_display', 'subject_Patient_value', 'period_start', 'period_start_date', 'period_start_time', 'period_end', 'period_end_date', 'period_end_time']\n",
    "consults = consults.rename(columns={'period_start_date' : 'created_date', 'period_start_time' : 'created_Time'})\n",
    "consults['created_date']= pd.to_datetime(consults['created_date'], format='%Y-%m-%d')\n",
    "\n",
    "# Drop outliers\n",
    "consults = consults[consults['period_end_date']!='2999-12-31']\n",
    "\n",
    "# Parse dates\n",
    "consults['period_start']= pd.to_datetime(consults['period_start'], format='%Y-%m-%d')\n",
    "consults['period_end']= pd.to_datetime(consults['period_end'], format='%Y-%m-%d')\n",
    "\n",
    "# Filter on relevant codes: \n",
    "physician_consults = consults[consults['type1_code'].isin(l_physician_codes)].copy()\n",
    "non_physician_consults = consults[~consults['type1_code'].isin(l_physician_codes)].copy()\n",
    "non_physician_consults = non_physician_consults.rename(columns={'type1_code' : 'RN_type1_code', 'type1_display' : 'RN_type1_display', 'period_start' : 'RN_period_start', 'period_end': 'RN_period_end'})\n",
    "\n",
    "print('Dataframe: Schedule data (n= %s; pat= %s)' % (len(consults), len(consults['subject_Patient_value'].unique())))\n",
    "print('Dataframe: Physician Schedule data (n= %s; pat= %s)' % (len(physician_consults), len(physician_consults['subject_Patient_value'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Match Schedule appointments to Mannequin data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tdmaarseveen/.conda/envs/ra_clustering2/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (3,10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe: Mannequin data (n= 1353291; pat= 18103)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Import Mannequin data with Sedimentation rate (BSE)\n",
    "################################################### UPDATE ####################################################\n",
    "das_data = pd.read_csv(r'../../new_data/offshoots/Dataplatform63/Clustering_Gewrichtspop_2023.csv', sep=';', parse_dates=True,)\n",
    "das_data = das_data.sort_values(by=['subject_Patient_value', 'created'])\n",
    "das_data['created']= pd.to_datetime(das_data['created'], format='%Y-%m-%d')\n",
    "das_data['authored']= pd.to_datetime(das_data['authored'], format='%Y-%m-%d')\n",
    "das_data = das_data.rename(columns={'item_text' : 'STELLING', 'PATNR' : 'subject_Patient_value', 'authored' : 'DATUM', 'created': 'MANNEQUIN_DATUM', 'BEHANDELAAR' : 'author_Person_value'})\n",
    "das_data['created_date'] = das_data['MANNEQUIN_DATUM'].dt.date\n",
    "das_data['created_date'] = pd.to_datetime(das_data['created_date'], format='%Y-%m-%d')\n",
    "\n",
    "print('Dataframe: Mannequin data (n= %s; pat= %s)' % (len(das_data), len(das_data['subject_Patient_value'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### select patients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_pat = pd.read_csv(r'../../new_data/offshoots/Dataplatform63/RA_patients_083_Selection.csv', sep='|')['PATNR'].unique()\n",
    "das_data = das_data[das_data['subject_Patient_value'].isin(l_pat)].copy()\n",
    "# das_data = das_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe: Joint data (n= 417301; pat=2247)\n"
     ]
    }
   ],
   "source": [
    "#ALTERNATIVE consults\n",
    "merge_consults = physician_consults.merge(das_data, how=\"inner\", on=[\"subject_Patient_value\",\"created_date\"])#.fillna(0).head(20)\n",
    "merge_consults\n",
    "\n",
    "print('Dataframe: Joint data (n= %s; pat=%s)' % (len(merge_consults), len(merge_consults['subject_Patient_value'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #2.1.1 Import treatment and consultations tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# import Medicator\n",
    "df_med = pd.read_csv('../../new_data/offshoots/Dataplatform63/Medication_REU_2023.csv', sep=';', header=None)\n",
    "df_med.columns = ['PATNR', 'periodOfUse_valuePeriod_start_date', 'periodOfUse_valuePeriod_end_date', 'usageDuration_valueDuration_value', 'dosageInstruction_text', 'dosageInstruction_additionalInstruction_text', 'dosageInstruction_timing_repeat_frequency', 'dosageInstruction_timing_repeat_period', 'dosageInstruction_route_display', 'dosageInstruction_doseQuantity_value', 'dosageInstruction_doseQuantity_unit_display_original', 'code_text', 'med.code4_GPK_code',  'ATC_code', 'ATC_display', 'ATC_display_nl']\n",
    "\n",
    "# In case the start date is missing fill with the end date\n",
    "df_med['periodOfUse_valuePeriod_start_date'] = df_med['periodOfUse_valuePeriod_start_date'].fillna(df_med['periodOfUse_valuePeriod_end_date'])\n",
    "df_med\n",
    "\n",
    "# Get first consult date\n",
    "df_pat = pd.read_csv(r'../../filters/RA_patients_AllNP_13-07-2023.csv', sep=',', index_col=0) # RA_patients_AllNP_11-10-2022\n",
    "\n",
    "d_pseudo_pat = dict(zip(df_pat.pseudoId, df_pat.patnr))\n",
    "d_pseudo_date = dict(zip(df_pat.pseudoId, df_pat.date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #2.1.2 Acquire date of first prescription\n",
    "Description: Acquire first date from baseline where a drug is prescriped for each pseudoId \n",
    "- The parameter no_drug_window ensures that there is no drug found prior to baseline for same patient (default = 6 months look behind) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'../../src/1_emr_scripts')\n",
    "import Preprocessing as func\n",
    "\n",
    "df_FirstTreat = func.getStartTreatmentDate(df_med, d_pseudo_pat, d_pseudo_date, no_drug_window=6)\n",
    "\n",
    "df_FirstTreat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #2.1.3 Export medication information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FirstTreat.to_csv('../../filters/RA_patients_AllNP_inclTreatmentStart_2023.csv', sep='|',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Mannequin filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3.1] Ensure mannequin data is before DMARD!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata complete (n=3069; pat=2345)\n",
      "Metadata without medication prior to \"baseline\" (n=2227; pat=1842)\n",
      "Metadata with medication after baseline (n=1967; pat=1682)\n",
      "Mannequin data before DMARD start (n=3081; pat=1421)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df_treat = pd.read_csv(r'../../filters/RA_patients_AllNP_inclTreatmentStart_2023.csv', sep='|')\n",
    "print('Metadata complete (n=%s; pat=%s)' % (len(df_treat), len(df_treat['patnr'].unique())))\n",
    "\n",
    "# Only keep those that do not have treatment before baseline moment (Default: look 6 months into the past)\n",
    "df_treat = df_treat[df_treat['Lookbehind_Treatment'].isna()].copy()\n",
    "print('Metadata without medication prior to \"baseline\" (n=%s; pat=%s)' % (len(df_treat), len(df_treat['patnr'].unique())))\n",
    "\n",
    "df_treat = df_treat[~df_treat['Lookahead_Treatment'].isna()].copy()\n",
    "df_treat['Lookahead_Treatment'] = pd.to_datetime(df_treat['Lookahead_Treatment'], format='%Y-%m-%d')\n",
    "\n",
    "\n",
    "df_treat['FILTER_RX_NA_BASELINE'] \n",
    "\n",
    "print('Metadata with medication after baseline (n=%s; pat=%s)' % (len(df_treat), len(df_treat['patnr'].unique())))\n",
    "\n",
    "df_man = pd.DataFrame()\n",
    "# Use first DMARD info\n",
    "d_firstTreat_all = dict(zip(df_treat['patnr'], df_treat['Lookahead_Treatment']))\n",
    "\n",
    "#for pseudoId in table\n",
    "for index, row in df_treat.iterrows():\n",
    "    pid = row['pseudoId']\n",
    "    pat = row['patnr']\n",
    "    firstman = np.nan\n",
    "    sub_df = merge_consults[merge_consults['subject_Patient_value']==pat].copy() \n",
    "    min_date = row['FirstConsult'] \n",
    "\n",
    "    # Convert string to datetime\n",
    "    min_date = pd.to_datetime(min_date, format='%Y-%m-%d', errors='ignore')\n",
    "    sub_df['created_date'] = pd.to_datetime(sub_df['created_date'], format='%Y-%m-%d', errors='ignore') # Voorheen DATUM\n",
    "    sub_df = sub_df.sort_values(by='created_date')\n",
    "\n",
    "    # define space where we will search for mannequin\n",
    "    max_date = pd.to_datetime(row['Lookahead_Treatment'], format='%Y-%m-%d', errors='ignore') \n",
    "    max_date = max_date + pd.DateOffset(days=1)  # add one day of tolerance \n",
    "    min_date = min_date - pd.DateOffset(days=1) # maybe a day earlier or 30 days?\n",
    "\n",
    "    # Search for mannequin\n",
    "    sub_df = sub_df[sub_df['created_date'].between(min_date, max_date, inclusive='both')]\n",
    "    sub_df['pseudoId'] = [row['pseudoId']] * len(sub_df)\n",
    "    df_man = pd.concat([df_man, sub_df])\n",
    "\n",
    "# only include those with mannequin inside RN at baseline\n",
    "print('Mannequin data before DMARD start (n=%s; pat=%s)' % (len(df_man['MANNEQUIN_DATUM'].unique()), len(df_man['subject_Patient_value'].unique())))\n",
    "merge_consults = df_man.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2346, 1421)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(consults['subject_Patient_value'].unique()), len(merge_consults['subject_Patient_value'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3.2] Check if RN appointment on the same date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_physician_codes = ['CO', 'NPA', 'NPS', 'SCO', 'CONSARTS', 'NP', 'NPS-D', 'NPAI', 'NPSO', 'NPSI', 'NPA-D', 'CO MDZ',\n",
    "                     'NPAI-D', 'NPSI-D', 'NPAS', 'NPSO-D', 'NPSS']\n",
    "\n",
    "consults['newindex'] = consults['created_date'].astype(str) + '_' + consults['subject_Patient_value'].astype(str)\n",
    "sub_consults = consults[consults['subject_Patient_value'].isin(merge_consults['subject_Patient_value'].unique())].copy()\n",
    "l_uniqvisits = list(sub_consults['newindex'].unique())\n",
    "d_visit_info = dict(zip(l_uniqvisits, [sub_consults[sub_consults['newindex']==vis]['type1_code'].unique() for vis in l_uniqvisits]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_rn_appointment(visitid):\n",
    "    return len(set(d_visit_info[visitid]) - set(l_physician_codes) ) != 0\n",
    "\n",
    "merge_consults['newindex'] = merge_consults['created_date'].astype(str) + '_' + merge_consults['subject_Patient_value'].astype(str)\n",
    "l_rn_appointment = list(filter(has_rn_appointment, d_visit_info.keys()))\n",
    "merge_consults['ScheduledRN'] = merge_consults['newindex'].apply(lambda x : 1 if x in l_rn_appointment else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3.3] Raise Flag when patients can be linked to atypical schedule appointments within same time window \n",
    "\n",
    "Use unfiltered consults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remainining entries (after filtering outside Physician window) (n=1143; pat=893)\n",
      "Polluted entries (both inside Physician & RN window) (n=1191; pat=29)\n",
      "Remainining entries (after filtering inside RN window) (n=1110; pat=875)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Flag if outside Physician window (make an exception: when there is no indication of RN on same date!)\n",
    "l_cols = ['created_date', 'subject_Patient_value', 'period_start', 'period_end', 'MANNEQUIN_DATUM']\n",
    "flag_consults = merge_consults.merge(non_physician_consults[['created_date', 'subject_Patient_value', 'RN_period_start', 'RN_period_end', 'RN_type1_code', 'RN_type1_display']], how=\"left\", on=[\"subject_Patient_value\",\"created_date\"])\n",
    "l_outsideWindow = flag_consults[(((flag_consults['period_start'] > flag_consults['MANNEQUIN_DATUM']) | (flag_consults['period_end'] < flag_consults['MANNEQUIN_DATUM'])) \n",
    "                                )].index\n",
    "\n",
    "flag_consults['Dubious_outsidePhys'] = np.where(flag_consults.index.isin(list(set(l_outsideWindow))), 1, 0)\n",
    "flag_consults['Dubious'] = np.where(flag_consults.index.isin(list(set(l_outsideWindow))), 1, 0)\n",
    "print('Remainining entries (after filtering outside Physician window) (n=%s; pat=%s)' % (len(flag_consults[flag_consults['Dubious']==0]['MANNEQUIN_DATUM'].unique()), len(flag_consults[flag_consults['Dubious']==0]['subject_Patient_value'].unique())))\n",
    "\n",
    "\n",
    "check_consults = flag_consults[~flag_consults['RN_type1_code'].isna()].copy()\n",
    "polluted = check_consults[(((check_consults['RN_period_end'] > check_consults['MANNEQUIN_DATUM']) & (check_consults['RN_period_start'] < check_consults['MANNEQUIN_DATUM'])) &\n",
    "    ((check_consults['period_start'] < check_consults['MANNEQUIN_DATUM']) & (check_consults['period_end'] > check_consults['MANNEQUIN_DATUM'])))].copy()\n",
    "print('Polluted entries (both inside Physician & RN window) (n=%s; pat=%s)' % (len(polluted), len(polluted['subject_Patient_value'].unique())))\n",
    "\n",
    "# Flag if inside RN window (except for when there is no indication of RN on same date? -> or can an RN window stretch across multiple dates)\n",
    "check_consults = check_consults[(((check_consults['RN_period_end'] > check_consults['MANNEQUIN_DATUM']) & (check_consults['RN_period_start'] < check_consults['MANNEQUIN_DATUM'])) | \n",
    "                                (check_consults['period_start'] > check_consults['MANNEQUIN_DATUM']) |\n",
    "                                (check_consults['period_end'] < check_consults['MANNEQUIN_DATUM']))]\n",
    "\n",
    "\n",
    "# Label doubtful entries\n",
    "flag_consults['Dubious_insideRN'] = np.where(flag_consults.index.isin(list(set(check_consults.index))), 1, 0)\n",
    "flag_consults['Dubious'] =  np.where(flag_consults.index.isin(list(set(check_consults.index))), 1, flag_consults['Dubious'])\n",
    "print('Remainining entries (after filtering inside RN window) (n=%s; pat=%s)' % (len(flag_consults[flag_consults['Dubious']==0]['MANNEQUIN_DATUM'].unique()), len(flag_consults[flag_consults['Dubious']==0]['subject_Patient_value'].unique())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3.4] Identify other RN / biobank indicators from consult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Temporary fix: supply with old extraction data (PAREL RAOA)\n",
    "das_data['created_date'] = pd.to_datetime(das_data['created_date'], format='%d-%m-%Y')\n",
    "das_data['DATUM'] = pd.to_datetime(das_data['DATUM'], format='%Y-%m-%d')\n",
    "l_other_studies = [i for i in list(das_data['description'].unique()) if i not in ['Gewrichtspop', np.nan]]\n",
    "\n",
    "# Note suspicious dates\n",
    "df_study = das_data[(das_data['description'].isin(l_other_studies))].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify entries linked to a suspicious date\n",
    "Motivation: in some cases we find that there are two mannequins on a single date! It might be that one of the mannequins is associated with a study cohort -> we might be able to identify RN mannequin as certain mannequins are associated with study cohort labels (such as PAREL RAOA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remainining entries (after filtering dubious Consults) (n=1110; pat=875)\n"
     ]
    }
   ],
   "source": [
    "COL_CATEGORY = 'description'\n",
    "\n",
    "\n",
    "df_remainder = flag_consults[flag_consults['Dubious']==0].copy()\n",
    "df_trustworthy = df_remainder.copy()\n",
    "\n",
    "# Identify entries for which we suspect they belong to a study cohort\n",
    "for pat in df_remainder['subject_Patient_value'].unique():\n",
    "    l_dates = list(df_study[(df_study['subject_Patient_value']==pat)]['created_date'].unique())\n",
    "    df_sub = df_study[((df_study['subject_Patient_value']==pat) & (df_study['subject_Patient_value'].isin(l_dates)))].copy()\n",
    "    for date in df_sub['created_date'].unique(): \n",
    "        # Acquire dates of suspicious mannequin entries\n",
    "        l_filter_dates = df_sub[((df_sub['created_date']==date) & (df_sub[COL_CATEGORY]!='Gewrichtspop'))]['DATUM'].unique()\n",
    "        if len(l_filter_dates) > 0:\n",
    "            df_trustworthy = df_trustworthy[~((df_trustworthy['subject_Patient_value']==pat) & (df_trustworthy['DATUM'].isin(l_filter_dates)))]\n",
    "\n",
    "# Update flagging\n",
    "flag_consults['Dubious'] = np.where(flag_consults.index.isin(list(set(df_remainder.index) - set(df_trustworthy.index))), 1, flag_consults['Dubious'])\n",
    "flag_consults['Dubious_consultInfo'] = np.where(flag_consults.index.isin(list(set(df_remainder.index) - set(df_trustworthy.index))), 1, 0)\n",
    "print('Remainining entries (after filtering dubious Consults) (n=%s; pat=%s)' % (len(flag_consults[flag_consults['Dubious']==0]['MANNEQUIN_DATUM'].unique()), len(flag_consults[flag_consults['Dubious']==0]['subject_Patient_value'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['type1_code', 'type1_display', 'subject_Patient_value', 'period_start',\n",
       "       'created_date', 'created_Time', 'period_end', 'period_end_date',\n",
       "       'period_end_time', 'identifier_value', 'STELLING',\n",
       "       'item_answer1_value_original', 'item_answer2_value_original',\n",
       "       'item_answer3_value_original', 'item_answer_valueCoding_display',\n",
       "       'DATUM', 'questionnaire_Questionnaire_value', 'description',\n",
       "       'author_Person_value', 'MANNEQUIN_DATUM', 'item_answer_lastUpdateDate',\n",
       "       'pseudoId', 'newindex', 'ScheduledRN', 'RN_period_start',\n",
       "       'RN_period_end', 'RN_type1_code', 'RN_type1_display',\n",
       "       'Dubious_outsidePhys', 'Dubious', 'Dubious_insideRN'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_remainder.columns#[['STELLING','questionnaire_Questionnaire_value']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3.5] Identify doublets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ONLY_INCONSISTENT = True # change to False if you would like to penalize all duplicates.\n",
    "df_remainder = flag_consults[flag_consults['Dubious']==0].copy() #[flag_consults['Dubious']==0].copy() # [flag_consults['Dubious']==0]\n",
    "df_trustworthy = df_remainder.copy()\n",
    "l_filter_dates = []\n",
    "\n",
    "# Drop rows of old con\n",
    "for pat in df_remainder['subject_Patient_value'].unique():\n",
    "    # \"subject_Patient_value\",\"created\", \"author_Person_value\"\n",
    "\n",
    "    df_sub = df_remainder[(df_remainder['subject_Patient_value']==pat)].copy()\n",
    "    for date in df_sub['created_date'].unique():\n",
    "        if ONLY_INCONSISTENT :\n",
    "            # Check for inconsistent duplicates on same date:\n",
    "            if len(df_sub[((df_sub['created_date']==date) & (df_sub['STELLING']=='Totaal gezwollen gewrichten'))]['item_answer1_value_original'].unique())>1:\n",
    "                print('Inconsistent duplicates found for %s at %s: %s' % (pat, date, list(df_sub[((df_sub['created_date']==date) & (df_sub['STELLING']=='Totaal gezwollen gewrichten'))]['item_answer1_value_original'])))\n",
    "                l_filter_dates = df_sub[((df_sub['created_date']==date) & (df_sub['STELLING']=='Totaal gezwollen gewrichten'))]['MANNEQUIN_DATUM'].unique()\n",
    "        else :\n",
    "            # Check for all duplicates\n",
    "            if len(df_sub[((df_sub['created_date']==date) & (df_sub['STELLING']=='Totaal gezwollen gewrichten'))])>1:\n",
    "                print('Duplicates found for %s at %s: %s' % (pat, date, list(df_sub[((df_sub['created_date']==date) & (df_sub['STELLING']=='Totaal gezwollen gewrichten'))]['item_answer1_value_original'])))\n",
    "                l_filter_dates = df_sub[((df_sub['created_date']==date) & (df_sub['STELLING']=='Totaal gezwollen gewrichten'))]['MANNEQUIN_DATUM'].unique()\n",
    "        df_trustworthy = df_trustworthy[~((df_trustworthy['subject_Patient_value']==pat) & (df_trustworthy['MANNEQUIN_DATUM'].isin(l_filter_dates)))]\n",
    "\n",
    "# Update flagging\n",
    "flag_consults['Dubious'] = np.where(flag_consults.index.isin(list(set(df_remainder.index) - set(df_trustworthy.index))), 1, flag_consults['Dubious'])\n",
    "flag_consults['Dubious_doubles'] = np.where(flag_consults.index.isin(list(set(df_remainder.index) - set(df_trustworthy.index))), 1, 0)\n",
    "print('Remainining entries (after filtering inconsistent duplicates) (n=%s; pat=%s)' % (len(flag_consults[flag_consults['Dubious']==0]['MANNEQUIN_DATUM'].unique()), len(flag_consults[flag_consults['Dubious']==0]['subject_Patient_value'].unique())))\n",
    "\n",
    "#print('Dubious entries (after inconsistent duplicate filter) (n=%s; pat=%s)' % (len(flag_consults[flag_consults['Dubious']==1]), len(flag_consults[flag_consults['Dubious']==1]['subject_Patient_value'].unique())))\n",
    "print('Final selection of entries (n=%s; pat=%s)' % (len(flag_consults[flag_consults['Dubious']==0]['MANNEQUIN_DATUM'].unique()), len(flag_consults[flag_consults['Dubious']==0]['subject_Patient_value'].unique())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3.6] Export physician mannequin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_interest = ['subject_Patient_value','author_Person_value',\n",
    "       'created_date', 'ID', 'STELLING', 'ANTWOORD', 'YANTWOORD',\n",
    "       'ZANTWOORD', 'XANTWOORD', 'DATUM', 'description', 'created'] # , 'pseudoId'\n",
    "\n",
    "flag_consults = flag_consults.rename(columns = {'identifier_value' : 'ID', 'item_answer_valueCoding_display' : 'XANTWOORD', 'item_answer1_value_original': 'ANTWOORD', 'item_answer2_value_original' : 'YANTWOORD', 'item_answer3_value_original': 'ZANTWOORD', 'MANNEQUIN_DATUM' : 'created'})\n",
    "flag_consults[flag_consults['Dubious']==0][l_interest].to_csv(r'../../new_data/offshoots/Dataplatform63/Gewrichtspop_REU_physician_2023.csv', sep=';', index=None)\n",
    "flag_consults[l_interest].to_csv(r'../../new_data/offshoots/Dataplatform63/Gewrichtspop_REU_Total_2023.csv', sep=';', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_consults.to_csv(r'../../new_data/offshoots/Dataplatform63/Gewrichtspop_REU_physician_VERBOSE.csv', sep=';', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3.7] Export putative RN mannequin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_ddra = pd.read_csv(r'../../new_data/offshoots/Dataplatform63/Gewrichtspop_REU_Total_2023.csv', sep=';')\n",
    "df_phys = pd.read_csv(r'../../new_data/offshoots/Dataplatform63/Gewrichtspop_REU_physician_2023.csv', sep=';')\n",
    "l_pat_phys = list(df_phys['subject_Patient_value'].unique())\n",
    "\n",
    "# Find patients that have a dubious origin\n",
    "l_dubious_pat =df_ddra[~df_ddra['subject_Patient_value'].isin(l_pat_phys)]['subject_Patient_value'].unique()\n",
    "\n",
    "# Export putative RN mannequins\n",
    "df_ddra[df_ddra['subject_Patient_value'].isin(l_dubious_pat)].to_csv(r'../../new_data/offshoots/Dataplatform63/Gewrichtspop_REU_PutativeRN.csv', sep=';', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clustering_ra",
   "language": "python",
   "name": "clustering_ra"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
