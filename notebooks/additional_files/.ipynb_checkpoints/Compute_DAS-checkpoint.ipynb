{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the DAS-score\n",
    "\n",
    "This script was created by my collegeau Nils Steinz.\n",
    "\n",
    "Sadly we are missing alot of DAS-scores, we can however compute DAS ourselves based on the components. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : Initialize important dictionaries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "das28 = [\n",
    "    \"pols links\", \"pols rechts\", \"pip 2 linkerhand\", \"pip 2 rechterhand\", \"pip 3 linkerhand\", \"pip 3 rechterhand\",\n",
    "    \"pip 4 linkerhand\", \"pip 4 rechterhand\",  \"pip 5 linkerhand\", \"pip 5 rechterhand\",\n",
    "    \"mcp 1 links\", \"mcp 1 rechts\", \"mcp 2 links\", \"mcp 2 rechts\", \"mcp 3 links\", \"mcp 3 rechts\",\n",
    "    \"mcp 4 links\", \"mcp 4 rechts\", \"mcp 5 links\", \"mcp 5 rechts\", \"ip links\", \"ip rechts\",\n",
    "    \"schouder links\", \"schouder rechts\", 'elleboog links', 'elleboog rechts', 'knie links', 'knie rechts'\n",
    "]\n",
    "das44 = das28 + [\n",
    "    'sternoclaviculair links', 'sternoclaviculair rechts', 'acromioclaviaculair rechts', 'acromioclaviculair links',\n",
    "    \"pip 2 linkervoet\", \"pip 2 rechtervoet\", \"pip 3 linkervoet\", \"pip 3 rechtervoet\",\n",
    "    \"pip 4 linkervoet\", \"pip 4 rechtervoet\",  \"pip 5 linkervoet\", \"pip 5 rechtervoet\",\n",
    "    \"bovenste spronggewricht links\", \"onderste spronggewricht links\",\n",
    "    \"bovenste spronggewricht rechts\",\"onderste spronggewricht rechts\"\n",
    "]    \n",
    "\n",
    "das44_t = [\"Gezwollen_\"+ \"_\".join(x.split()) for x in das44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_map = {'IP links': 'ip links', \n",
    " 'IP rechts':'ip rechts',\n",
    " 'IP voet links':'ip linkervoet',\n",
    " 'IP voet rechts':'ip rechtervoet',\n",
    " 'Manubrio sternaal gewricht':'manubrio sternaal gewricht',\n",
    " 'acromioclaviaculair L':'acromioclaviculair links',\n",
    " 'acromioclaviaculair R':'acromioclaviaculair rechts',\n",
    " 'bovenste spronggewicht links':'bovenste spronggewricht links',\n",
    " 'cmc 1 links':'cmc 1 links',\n",
    " 'cmc 1 rechts':'cmc 1 rechts',\n",
    " 'dip 2 links':'dip 2 linkerhand',\n",
    " 'dip 2 links voet':'dip 2 linkervoet',\n",
    " 'dip 2 rechts':'dip 2 rechterhand',\n",
    " 'dip 2 rechts voet':'dip 2 rechtervoet',\n",
    " 'dip 3 links':'dip 3 linkerhand',\n",
    " 'dip 3 links voet':'dip 3 linkervoet',\n",
    " 'dip 3 rechts':'dip 3 rechterhand',\n",
    " 'dip 3 rechts voet':'dip 3 rechtervoet',\n",
    " 'dip 4 links':'dip 4 linkerhand',\n",
    " 'dip 4 links voet':'dip 4 linkervoet',\n",
    " 'dip 4 rechts':'dip 4 rechterhand',\n",
    " 'dip 4 rechts voet':'dip 4 rechtervoet',\n",
    " 'dip 5 links':'dip 5 linkerhand',\n",
    " 'dip 5 links voet':'dip 5 linkervoet',\n",
    " 'dip 5 rechts':'dip 5 rechterhand',\n",
    " 'dip 5 rechts voet':'dip 5 rechtervoet',\n",
    " 'Elleboog L':'elleboog links',\n",
    " 'elleboog R':'elleboog rechts',\n",
    " 'pip 2 links hand':'pip 2 linkerhand',\n",
    " 'pip 2 links voet':'pip 2 linkervoet',\n",
    " 'pip 2 rechts hand':'pip 2 rechterhand',\n",
    " 'pip 2 rechts voet':'pip 2 rechtervoet',\n",
    " 'pip 3 links hand':'pip 3 linkerhand',\n",
    " 'pip 3 links voet':'pip 3 linkervoet',\n",
    " 'pip 3 rechts hand':'pip 3 rechterhand',\n",
    " 'pip 3 rechts voet':'pip 3 rechtervoet',\n",
    " 'pip 4 links hand':'pip 4 linkerhand',\n",
    " 'pip 4 links voet': 'pip 4 linkervoet',\n",
    " 'pip 4 rechts hand':'pip 4 rechterhand',\n",
    " 'pip 4 rechts voet':'pip 4 rechtervoet',\n",
    " 'pip 5 links hand':'pip 5 linkerhand',\n",
    " 'pip 5 links voet':'pip 5 linkervoet',\n",
    " 'pip 5 rechts hand':'pip 5 rechterhand',\n",
    " 'pip 5 rechts voet':'pip 5 rechtervoet',\n",
    " 'pols L':'pols links',\n",
    " 'pols R':'pols rechts',\n",
    " 'schouder L':'schouder links',\n",
    " 'schouder R':'schouder rechts',\n",
    " 'sternoclaviculair L':'sternoclaviculair links',\n",
    " 'sternoclaviculair R':'sternoclaviculair rechts',\n",
    " 'tarsometatarsaal L':'tarsometatarsaal Links',\n",
    " 'tarsometatarsaal R':'tarsometatarsaal Rechts',\n",
    " 'temporomandibulair L':'temporomandibulair links',\n",
    " 'temporomandibulair R':'temporomandibulair rechts'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivot_data(dataframe:pd.DataFrame, which: str, prefix:str=\"Pijn\", JC_name:str=\"TJC\" ) -> pd.DataFrame:\n",
    "    df = dataframe[[\"PATNR\",\"DATUM\",\"STELLING\",\"XANTWOORD\",\"M_DATUM\"]][dataframe[\"STELLING\"] == which].copy()\n",
    "    df['value'] = 1\n",
    "    df = df.pivot_table(index=(\"PATNR\",\"DATUM\"), columns=\"XANTWOORD\", values=\"value\",fill_value=0)\n",
    "    df = df.rename(columns=name_map)\n",
    "    df[\"total \"+which] = df.sum(axis=1)\n",
    "    df[JC_name+\"_28\"] = df[das28].sum(axis=1)\n",
    "    df[JC_name+\"_44\"] = df[das44].sum(axis=1)\n",
    "    renaming = {x:prefix+\"_\"+\"_\".join(x.split(\" \")) for x in df.columns[:-3]}\n",
    "    df = df.rename(columns=renaming)\n",
    "    return df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Process data\n",
    "### Import Mannequin & ESR information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tdmaarseveen/.conda/envs/ra_clustering2/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (5,6,7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# Import Mannequin data with Sedimentation rate (BSE)\n",
    "################################################### UPDATE ####################################################\n",
    "data = pd.read_csv(r'/exports/reum/tdmaarseveen/RA_Clustering/new_data/1_raw/Clustering_Gewrichtspop_with_BSE.csv', sep='|')\n",
    "data['DATUM_A'] = pd.to_datetime(data['DATUM_A'], format='%Y-%m-%d')\n",
    "data = data.sort_values(by=['PATNR', 'DATUM_A'])\n",
    "\n",
    "# Remove weird data artefacts\n",
    "data = data[~((data['STELLING']=='Pijn') & (data['XANTWOORD'].str.contains('OBJECTID')==True))]\n",
    "data = data[~((data['STELLING']=='Zwelling') & (data['XANTWOORD'].str.contains('OBJECTID')==True))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'/exports/reum/tdmaarseveen/RA_Clustering/new_data/1_raw/Clustering_Gewrichtspop_with_BSE.csv', sep='|')\n",
    "data[data['PATNR']==304862631]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We use DATUM_A (as it is the actual date of consult)\n",
    "The other column 'DATUM' refers to the mutation date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(wd+\"New data/StringentPatSelection_Mannequin_Variables.csv\", sep=\"|\", parse_dates=True,)\n",
    "data[\"M_DATUM\"] = data.DATUM.copy()\n",
    "data.DATUM = pd.to_datetime(data.DATUM_A, format='%Y-%m-%d')\n",
    "data['DATUM'] = data['DATUM'].dt.date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link to schedule appointments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_cols = ['subject_Patient_value', 'description', 'created_date']\n",
    "\n",
    "consults = pd.read_csv(r'/exports/reum/tdmaarseveen/RA_Clustering/new_data/offshoots/DAS_check/DF_REU_Schedule_validate.csv', sep=';', parse_dates=True, header=None)\n",
    "consults.columns = ['type1_code', 'description', 'subject_Patient_value', 'period_start', 'period_start_date', 'period_start_time', 'period_end', 'period_end_date', 'period_end_time']\n",
    "consults = consults.rename(columns={'period_start_date' : 'created_date', 'period_start_time' : 'created_Time'})\n",
    "consults['created_date']= pd.to_datetime(consults['created_date'], format='%Y-%m-%d')\n",
    "\n",
    "consults = consults.sort_values(by=['created_date'])\n",
    "consults = consults.rename(columns={'subject_Patient_value' : 'PATNR', 'created_date' : 'DATUM'})\n",
    "consults['DATUM']= pd.to_datetime(consults['DATUM'], format='%Y-%m-%d')\n",
    "data['DATUM']= pd.to_datetime(data['DATUM'], format='%Y-%m-%d')\n",
    "\n",
    "data_bse = data.copy()\n",
    "# Be careful: you join on matching date with consults -> you might loose additional information (that matches imperfectly)\n",
    "data = consults.merge(data, how=\"right\", on=[\"PATNR\",\"DATUM\"])#.fillna(0).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform mannequin info from long to wide\n",
    "\n",
    "- For both swollen and painful joints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggdf = pivot_data(dataframe=data, which=\"Zwelling\", prefix= \"Gezwollen\", JC_name=\"SJC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgdf = pivot_data(dataframe=data, which=\"Pijn\", prefix= \"Pijn\", JC_name=\"TJC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine swollen & pain into one supertable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pgdf.merge(ggdf, how=\"outer\", on=[\"PATNR\",\"DATUM\"]).fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add exception whereby patient doesnt have any swollen or tender joints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No tender joints\n",
    "df = data[[\"PATNR\",\"DATUM\",\"STELLING\",\"XANTWOORD\",\"M_DATUM\"]][((data[\"STELLING\"] == \"Geen pijnlijke gewrichten\") |\n",
    "                                                            ((data[\"STELLING\"] == \"Pijnlijke gewrichten\") & (data[\"ANTWOORD\"] == \"geen.\")))].copy()\n",
    "df[\"value\"] = 1\n",
    "test_pg = df.pivot_table(index=(\"PATNR\",\"DATUM\"), columns=\"STELLING\", values=\"value\",fill_value=0)\n",
    "\n",
    "# No swollen joints\n",
    "df = data[[\"PATNR\",\"DATUM\",\"STELLING\",\"XANTWOORD\",\"M_DATUM\"]][((data[\"STELLING\"] == \"Geen gezwollen gewrichten\") |\n",
    "                                                            ((data[\"STELLING\"] == \"Gezwollen gewrichten\") & (data[\"ANTWOORD\"] == \"geen.\")))].copy()\n",
    "df[\"value\"] = 1\n",
    "test_gg =df.pivot_table(index=(\"PATNR\",\"DATUM\"), columns=\"STELLING\", values=\"value\",fill_value=0)\n",
    "\n",
    "\n",
    "test_merge = test_gg.merge(test_pg, how=\"outer\",left_index=True, right_index=True).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.merge(test_merge, how=\"outer\", on=[\"PATNR\",\"DATUM\"]).fillna(0).drop([\"Geen gezwollen gewrichten\", \"Geen pijnlijke gewrichten\", \"Gezwollen gewrichten\", \"Pijnlijke gewrichten\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare DAS vs Non-DAS joints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "l_nonDas = set(list(data[((data['STELLING']=='Pijn') & (data['CATEGORIE']=='Gewrichtspop'))]['XANTWOORD'].unique())) - set(das44)\n",
    "l_nonDas = [col for col in l_nonDas if col==col]\n",
    "l_nonDas = [col for col in l_nonDas if 'pip' not in col and 'schouder' not in col and 'Elleboog' not in col and 'elleboog' not in col and 'IP' not in col and 'pols' not in col]\n",
    "\n",
    "l_Das = set(list(data[((data['STELLING']=='Pijn') & (data['CATEGORIE']=='Gewrichtspop'))]['XANTWOORD'].unique())) - set(l_nonDas)\n",
    "l_Das = [col for col in l_Das if col==col]\n",
    "l_Das = [col for col in l_Das if 'voet' not in col and 'sprong' not in col]\n",
    "\n",
    "\n",
    "#for joint in l_Das:\n",
    "#    print(\"unique values= %s, n= %s Joint= '%s';\" % (data[data['XANTWOORD']==joint]['ZANTWOORD'].unique(), len(data[data['XANTWOORD']==joint]), joint))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquire DAS44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d44 = data[data[\"STELLING\"] == \"DAS 44\"][[\"PATNR\",\"DATUM\",\"STELLING\",\"ANTWOORD\"]]\n",
    "d44[\"value\"] = d44.ANTWOORD.str.rstrip('\"').str.replace(',', '.').str.rsplit(\"VALUE1=\",expand=True)[1].astype(np.float64)\n",
    "d44.groupby(\"PATNR\").head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquire ESR (BSE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BSE = data_bse[data_bse[\"STELLING\"] == \"BSE\"][[\"PATNR\",\"DATUM\",\"STELLING\",\"ANTWOORD\"]]\n",
    "BSE[\"bse\"] = BSE.ANTWOORD.astype(np.float64)\n",
    "BSE = BSE.dropna() # somehow there are still some rows with NA?\n",
    "BSE = BSE.drop(\"STELLING\", axis=1).drop(\"ANTWOORD\", axis=1)\n",
    "BSE.groupby(\"PATNR\").head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Link Mannequin to Lab data (for ESR component)\n",
    "\n",
    "### Combine ESR with mannequin data (for downstream DAS calculation)\n",
    "\n",
    "Forward tolerance = 14 days (looking in the future)  \n",
    "Backward tolerance = 14 days (looking in the past)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.groupby('PATNR').merge_asof(BSE.groupby('PATNR'), by='DATUM', tolerance=TOL_BEFORE, direction='nearest')\n",
    "TOL_BEFORE = 14\n",
    "TOL_AFTER = 14\n",
    "\n",
    "df_back = pd.merge_asof(dataset[['PATNR', 'DATUM']].sort_values(by='DATUM'), BSE.sort_values(by='DATUM'), by='PATNR', on='DATUM', tolerance=pd.Timedelta(days=TOL_BEFORE), direction='backward') #\n",
    "df_forward = pd.merge_asof(dataset[['PATNR', 'DATUM']].sort_values(by='DATUM'), BSE.sort_values(by='DATUM'), by='PATNR', on='DATUM', tolerance=pd.Timedelta(days=TOL_AFTER), direction='forward')\n",
    "\n",
    "# Link Mannequin to ESR\n",
    "df_backfo = df_forward.merge(df_back, on=['PATNR','DATUM'],how='outer')\n",
    "df_backfo['bse'] = df_backfo['bse_x'].fillna(df_backfo['bse_y'])\n",
    "df_backfo['key'] = df_backfo['PATNR'].astype(str) + '_' + df_backfo['DATUM'].astype(str)\n",
    "d_esr = dict(zip(df_backfo.key, df_backfo.bse))\n",
    "\n",
    "dataset['key'] = dataset['PATNR'].astype(str) + '_' + dataset['DATUM'].astype(str)\n",
    "dataset['bse'] = dataset['key'].apply(lambda x : d_esr[x])\n",
    "\n",
    "\n",
    "# Calculate nr of elapsed days\n",
    "df_treat = pd.read_csv('../../filters/RA_patients_AllNP_inclTreatmentStart.csv', sep='|')\n",
    "new_pat = dict(zip(df_treat.patnr, df_treat.FirstConsult)) # First consult\n",
    "\n",
    "# Determine first consult data\n",
    "dataset['PEC']= dataset['PATNR'].apply(lambda x: new_pat[x] if x in new_pat.keys() else np.nan)\n",
    "dataset['PEC'] = pd.to_datetime(dataset['PEC'], format='%Y-%m-%d')\n",
    "dataset['days'] = ((dataset['DATUM'] - dataset['PEC']) / np.timedelta64(1, 'D')).astype(int)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_pass = ['SJC_28', 'SJC_44','TJC_28', 'TJC_44', 'DATUM', 'PATNR', 'total Zwelling', 'total Pijn', 'bse', 'days', 'PEC']\n",
    "\n",
    "das_df = dataset[l_pass].copy()\n",
    "das_df.rename(columns= {'PATNR' : 'patnr','DATUM' : 'date'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Calculate DAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_DAS28(tjc, sjc, esr):\n",
    "    \"\"\"\n",
    "    Calculate DAS28 with 3 variables : TJC, SJC and ESR (BSE)\n",
    "    \"\"\"\n",
    "    #print(esr)\n",
    "    if esr != 0:\n",
    "        das28 = (0.56 * np.sqrt(tjc) + 0.28 * np.sqrt(sjc) + 0.70 * np.log(esr)) * 1.08 + 0.16\n",
    "    else :\n",
    "        print(esr, tjc, sjc)\n",
    "        print(eql)\n",
    "    #print(das28)\n",
    "    return das28\n",
    "\n",
    "def calculate_DAS44(tjc, sjc, esr):\n",
    "    \"\"\"\n",
    "    Calculate DAS44 with 3 variables : RAI, SJC and ESR (BSE)\n",
    "    \"\"\"\n",
    "\n",
    "    das44= (0.53938 * np.sqrt(tjc) + 0.0650 * (sjc) + 0.330 * np.log(esr)) + 0.224 \n",
    "    return das44\n",
    "\n",
    "\n",
    "\n",
    "# Fill in missing DAS (altenrative: get DAS from df rn1.TotalDAS44)\n",
    "das_df['DAS28(3)'] = das_df.apply(lambda x : calculate_DAS28(x['TJC_28'],x['SJC_28'] ,x['bse'] ), axis=1)\n",
    "das_df['DAS44'] = das_df.apply(lambda x : calculate_DAS44(x['TJC_44'],x['SJC_44'] ,x['bse'] ), axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: export DAS calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "das_df = das_df.rename(columns={'SJC_28': 'SJC', 'TJC_28': 'TJC', 'bse' : 'ESR', 'PATNR':'patnr', 'DATUM': 'date', 'DAS28' : 'DAS28(3)'})\n",
    "das_df = das_df.dropna()\n",
    "das_df.to_csv('../../new_data/7_final/DAS_patients.csv', sep = ';', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clustering_ra",
   "language": "python",
   "name": "clustering_ra"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
